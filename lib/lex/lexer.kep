/**
 * @fileOverview Khepri lexers.
 */
package (
    literal,
    token,
    inputElementRegExp,
    lexer,
    lexManyState,
    lex)
with
    import 'parse/parse' parse {
        always,
        attempt,
        binds,
        bind,
        choice,
        either,
        eof,
        getPosition,
        enumeration,
        extract,
        expected,
        next,
        many,
        runState,
        Parser,
        ParserState},
    import 'nu/stream' {memoStream, 'end': NIL, 'from': streamFrom},
    import 'khepri_ast/token' lexToken,
    import 'khepri/position' {SourceLocation, SourcePosition},
    import 'khepri/lex/boolean_lexer' {booleanLiteral},
    import 'khepri/lex/comment_lexer' {comment},
    import 'khepri/lex/identifier_lexer' {identifier},
    import 'khepri/lex/line_terminator_lexer' {lineTerminator},
    import 'khepri/lex/null_lexer' {nullLiteral},
    import 'khepri/lex/number_lexer' {numericLiteral},
    import 'khepri/lex/punctuator_lexer' {punctuator},
    import 'khepri/lex/reserved_word_lexer' {reservedWord},
    import 'khepri/lex/string_lexer' {stringLiteral},
    import 'khepri/lex/whitespace_lexer' {whitespace},
    import 'khepri/lex/regular_expression_lexer' {regularExpressionLiteral}
in {

var makeToken = \type, p ->
    binds(
        enumeration(
            getPosition,
            p,
            getPosition),
        \start, value, end ->
            always(
                new type(
                    new SourceLocation(start, end),
                    value)));

/* Lexers
 ******************************************************************************/
literal = choice(
    makeToken(lexToken.StringToken, stringLiteral)
        |> (expected, "string literal"),
    makeToken(lexToken.RegularExpressionToken, regularExpressionLiteral)
        |> (expected, "regular expression literal"),
    makeToken(lexToken.BooleanToken, booleanLiteral)
        |> (expected, "boolean literal"),
    makeToken(lexToken.NullToken, nullLiteral)
        |> (expected, "null literal"),
    makeToken(lexToken.NumberToken, numericLiteral)
        |> (expected, "number literal"));

token = choice(
    attempt
        <| makeToken(lexToken.IdentifierToken, identifier)
        |> (expected, "identifier"),
    attempt
        <| literal,
    attempt
        <| makeToken(lexToken.KeywordToken, reservedWord)
        |> (expected, "reserved word"),
    makeToken(lexToken.PunctuatorToken, punctuator)
        |> (expected, "puctuator"));

inputElementRegExp = choice(
    makeToken(lexToken.CommentToken, comment)
        |> (expected, "comment"),
    makeToken(lexToken.WhitespaceToken, whitespace)
        |> (expected, "whitespace"),
    makeToken(lexToken.LineTerminatorToken, lineTerminator)
        |> (expected, "line terminator"),
    token);

lexer = many(inputElementRegExp);

/* Running
 ******************************************************************************/
lexManyState = \p, state -> let 
    manyP = either(
        bind(p, \x, state, m ->
            always(memoStream(x, (runState, manyP, state, m)))),
        next(eof, always(NIL)))
in
    runState(manyP, state);

lex = \input ->
    lexManyState(
        inputElementRegExp,
        new ParserState(
            streamFrom(input),
            new SourcePosition(0, 0)));

}